{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import datetime\n",
    "import skimage.measure\n",
    "import json\n",
    "import skimage\n",
    "from skimage.measure import find_contours, approximate_polygon"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "def read_xray(path, voi_lut = True, fix_monochrome = True):\n",
    "    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n",
    "    dicom = pydicom.read_file(path)\n",
    "    \n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n",
    "    # \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "               \n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "        \n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "        \n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def resize(array):\n",
    "    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n",
    "    im = Image.fromarray(array)\n",
    "    \n",
    "#     if keep_ratio:\n",
    "#         im.thumbnail((size, size), resample)\n",
    "#     else:\n",
    "#         im = im.resize((size, size), resample)\n",
    "    \n",
    "    return im"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for split in ['test']:\n",
    "    load_dir = f'../input/body-morphometry-kidney-and-tumor/{split}/DICOM/'\n",
    "    save_dir = f'/kaggle/tmp/{split}/'\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for path in tqdm(os.listdir(load_dir)):\n",
    "        # set keep_ratio=True to have original aspect ratio\n",
    "        for file in os.listdir(os.path.join(load_dir, path)):\n",
    "            xray = read_xray(os.path.join(load_dir, path, file))\n",
    "            im = resize(xray)  \n",
    "            im.save(os.path.join(save_dir, path + file).replace('dcm', 'png'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class KidneyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, label_dir, transform=None):\n",
    "        \n",
    "        self.label_dirs = sorted(glob(label_dir))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        img = cv2.imread(self.label_dirs[index])\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "            \n",
    "        return self.label_dirs[index], img\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label_dirs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_dataset = KidneyDataset('/kaggle/tmp/test/*', transform = test_transform)\n",
    "test_loader = DataLoader(dataset=test_dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.path.append('../input/segmentation-modelspytorch')\n",
    "\n",
    "import segmentation_models_pytroch as smp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = smp.Unet(encoder_name='tu-efficientnetv2_rw_m', encoder_weights = None, classes=3 , activation=None)\n",
    "model = model.to(device)\n",
    "\n",
    "model_path = '../input/efficientnet-baseline/effi2unet_baseline.pt'\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def rle_encode(mask_image):\n",
    "    pixels = mask_image.flatten()\n",
    "    # We avoid issues with '1' at the start or end (at the corners of\n",
    "    # the original image) by setting those pixels to '0' explicitly.\n",
    "    # We do not expect these to be non-zero for an accurate mask,\n",
    "    # so this should not harm the score.\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "    return runs\n",
    "\n",
    "\n",
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f = open('./submission.csv', \"w\")\n",
    "f.write(\"Id,EncodedPixels\\n\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print('Start prediction...')\n",
    "\n",
    "for i, (info, img) in tqdm(enumerate(test_loader), total = len(test_loader)):\n",
    "\n",
    "    if i % 64 == 0:\n",
    "        data_id_1 = f'test{format((i//64) + 1, \"03\")}_{1}'\n",
    "        data_id_2 = f'test{format((i//64) + 1, \"03\")}_{2}'\n",
    "\n",
    "        mask_stack1 = np.array([], dtype='uint8')\n",
    "        mask_stack2 = np.array([], dtype='uint8')\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        # imgs - 1,3,512,512\n",
    "        \n",
    "        outs = model(img.to(device)) # 1,3,512,512\n",
    "        outs = torch.argmax(outs, dim=1).detach().cpu().numpy() # (1,512,512)\n",
    "        \n",
    "        mask_stack1 = np.hstack([mask_stack1, np.array(outs[0] == 1).flatten()])\n",
    "        mask_stack2 = np.hstack([mask_stack2, np.array(outs[0] == 2).flatten()])\n",
    "    \n",
    "    if (i + 1) % 64==0:\n",
    "        enc = rle_to_string(rle_encode(mask_stack1))\n",
    "        line = f'{data_id_1},{enc}'\n",
    "        f.write(line + '\\n')\n",
    "        \n",
    "        enc = rle_to_string(rle_encode(mask_stack2))\n",
    "        line = f'{data_id_2},{enc}'\n",
    "        f.write(line + '\\n')\n",
    "        \n",
    "f.close()\n",
    "\n",
    "print('DONE!')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}